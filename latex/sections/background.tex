\section{Technical Background}

\subsection{Problem Setting and Evaluation}
We study a supervised regression problem in which a model learns a mapping from
tabular input features to a continuous target variable, namely student exam
scores. Given labeled samples $\{(x_i, y_i)\}_{i=1}^N$, the goal is to learn a
function that generalizes well to unseen data \cite{hastie2009elements}.

Model performance is evaluated using \emph{Root Mean Squared Error (RMSE)}:
\begin{equation}
\mathrm{RMSE} = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(y_i - \hat{y}_i)^2}.
\end{equation}
RMSE is the official evaluation metric of the Kaggle competition considered in
this work and penalizes large prediction errors more strongly than absolute-error
metrics \cite{kagglemetrics}.

\subsection{Tree-Based Models and Gradient Boosting}
Tree-based models capture nonlinear relationships and feature interactions by
partitioning the feature space with decision rules. While individual decision
trees are flexible, they often suffer from high variance \cite{hastie2009elements}.
Gradient Boosted Decision Trees (GBDTs) address this limitation by constructing
trees sequentially, where each new tree corrects the residual errors of the
current ensemble \cite{friedman2001gbm}.

We evaluate three widely used GBDT implementations. XGBoost employs level-wise
tree growth with strong regularization \cite{xgboost}. LightGBM adopts a
leaf-wise growth strategy for improved efficiency and accuracy on large datasets,
at the cost of increased overfitting risk \cite{lightgbm}. CatBoost is designed
for datasets with categorical features, using ordered boosting and native
categorical encoding to reduce target leakage \cite{catboost}.

\subsection{Ensemble Learning and Cross-Validation}
Ensemble learning combines predictions from multiple models to improve robustness
and predictive performance by exploiting complementary model strengths
\cite{zhou2012ensemble}. To obtain reliable estimates of generalization
performance and enable fair model comparison, we use $k$-fold cross-validation,
which reduces sensitivity to a single train--test split \cite{kohavi1995cv}.

\subsection{Neural Networks for Tabular Data}
Recent neural architectures have shown competitive performance on tabular data,
challenging the dominance of gradient boosting methods. A key component enabling
this is the use of \emph{entity embeddings}, which map categorical features to
dense vector representations and allow the model to learn semantic relationships
between categories.

To model complex nonlinear interactions, deep networks often employ residual
connections, which stabilize training of deeper architectures, and
Squeeze-and-Excitation (SE) blocks, which adaptively reweight feature channels to
emphasize informative inputs. These mechanisms allow neural models to learn
instance-specific feature importance rather than relying on static splits.

\subsection{Model Interpretability}
To interpret model predictions, we use SHAP (SHapley Additive exPlanations), a
game-theoretic framework that attributes a modelâ€™s output to individual input
features \cite{lundbergUnifiedApproachInterpreting2017}. SHAP values decompose a
prediction into additive feature contributions relative to an expected baseline,
enabling both local and global explanations.

For tree-based models, SHAP values can be computed efficiently using
TreeExplainer \cite{lundbergLocalExplanationsGlobal2020}. Global feature importance
is obtained by aggregating absolute SHAP values across samples, providing insight
into which features most strongly influence predictions while accounting for
feature interactions \cite{lundbergExplainableMachinelearningPredictions2018}.

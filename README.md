# Student Test Score Prediction - Kaggle Playground Series S6E1

Modular machine learning codebase for the Kaggle Playground Series S6E1 competition. Includes traditional models, gradient boosting, custom SE-ResNet architecture, and an IEEE conference paper.

## ğŸ“ Project Structure

```
MLCV_Kaggle/
â”œâ”€â”€ data/                      # Dataset files
â”‚   â”œâ”€â”€ train.csv             # Training data
â”‚   â”œâ”€â”€ test.csv              # Test data
â”‚   â””â”€â”€ sample_submission.csv # Submission format
â”‚
â”œâ”€â”€ src/                       # Modular source code
â”‚   â”œâ”€â”€ config.py             # Global configuration and hyperparameters
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ loader.py         # Data loading utilities
â”‚   â”‚   â””â”€â”€ features.py       # Feature engineering functions
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ base.py           # Base model class
â”‚   â”‚   â”œâ”€â”€ ridge.py          # Ridge regression
â”‚   â”‚   â”œâ”€â”€ random_forest.py  # Random Forest
â”‚   â”‚   â”œâ”€â”€ lightgbm_model.py # LightGBM implementation
â”‚   â”‚   â”œâ”€â”€ xgboost_model.py  # XGBoost implementation
â”‚   â”‚   â”œâ”€â”€ catboost_model.py # CatBoost implementation
â”‚   â”‚   â”œâ”€â”€ senet.py          # SE-ResNet neural network
â”‚   â”‚   â””â”€â”€ ensemble.py       # Ensemble methods
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ cross_validation.py # CV framework
â”‚   â”‚   â””â”€â”€ tuning.py         # Hyperparameter optimization
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â””â”€â”€ metrics.py        # Evaluation metrics
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ plots.py          # Plotting utilities
â”‚
â”œâ”€â”€ scripts/                   # Executable scripts
â”‚   â”œâ”€â”€ run_eda.py            # Exploratory data analysis
â”‚   â”œâ”€â”€ run_training.py       # Train models with CV
â”‚   â”œâ”€â”€ run_tuning.py         # Bayesian hyperparameter tuning
â”‚   â”œâ”€â”€ run_stacking.py       # Stacking ensemble
â”‚   â”œâ”€â”€ run_senet.py          # SE-ResNet training
â”‚   â”œâ”€â”€ run_shap_analysis.py  # SHAP interpretability
â”‚   â”œâ”€â”€ run_submission.py     # Generate submission file
â”‚
â”œâ”€â”€ outputs/                   # Generated outputs
â”‚   â”œâ”€â”€ figures/              # Visualizations
â”‚   â”œâ”€â”€ models/               # Saved model files
â”‚   â””â”€â”€ results/              # JSON results and metrics
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                 # This file
```

## ğŸš€ Installation

```bash
# Clone repository
git clone <repository-url>
cd MLCV_Kaggle

# Install dependencies
pip install -r requirements.txt
```

## ğŸ”§ Usage

### Running Analysis and Training

```bash
# 1. Exploratory Data Analysis
python scripts/run_eda.py
# Generates visualizations in outputs/figures/

# 2. Train all models with cross-validation
python scripts/run_training.py
# Trains Ridge, Random Forest, LightGBM, XGBoost, CatBoost

# 3. Hyperparameter tuning (optional)
python scripts/run_tuning.py
# Bayesian optimization for gradient boosting models

# 4. Train SE-ResNet neural network
python scripts/run_senet.py
# Custom deep learning model with entity embeddings

# 5. Run SHAP analysis
python scripts/run_shap_analysis.py
# Generate feature importance visualizations

# 6. Generate Kaggle submission
python scripts/run_submission.py
# Creates submission.csv with predictions
```

## ğŸ“ Building the Paper

The `latex/` directory contains the IEEE conference paper source:

```bash
cd latex/
pdflatex main.tex
bibtex main
pdflatex main.tex
pdflatex main.tex
```

Output: `main.pdf`

## âš™ï¸ Configuration

All settings are centralized in `src/config.py`:

- **Paths**: Data directories, output locations
- **Hyperparameters**: Model-specific parameters for all algorithms
- **Seeds**: Random seed for reproducibility (default: 42)
- **Cross-validation**: Number of folds (default: 5)
- **Features**: Column definitions (numerical/categorical)
- **Plotting**: DPI, style, colors

## ğŸ“¦ Code Organization

### Design Principles
- **Modular**: Separated concerns (data, models, training, evaluation)
- **Reusable**: Base classes with consistent interfaces
- **Configurable**: Centralized configuration management
- **Reproducible**: Fixed random seeds, version-controlled
- **Maintainable**: Clean structure with docstrings

### Key Modules

**`src/data/`** - Data handling
- Data loading and preprocessing
- Feature engineering (interactions, polynomials, target encoding)
- CV-safe transformations

**`src/models/`** - Model implementations
- Base class for unified interface
- Sklearn/LightGBM/XGBoost/CatBoost wrappers
- Custom SE-ResNet implementation (PyTorch)

**`src/training/`** - Training utilities
- Cross-validation framework
- Hyperparameter optimization (Bayesian)
- Model checkpointing

**`src/evaluation/`** - Evaluation tools
- RMSE and other metrics
- Residual analysis
- Model comparison

**`src/visualization/`** - Plotting
- EDA visualizations
- Feature importance plots
- SHAP visualizations

## ğŸ¯ Workflow

Standard workflow for reproducing results:

1. Place data files in `data/` directory
2. Run `python scripts/run_eda.py` to understand the data
3. Run `python scripts/run_training.py` to train baseline and boosting models
4. Run `python scripts/run_senet.py` to train deep learning model
5. Run `python scripts/run_submission.py` to generate predictions
6. (Optional) Run `python scripts/run_shap_analysis.py` for interpretability

All outputs (figures, models, results) saved in `outputs/`.

## ğŸ‘¥ Team

University of Porto (FEUP) - Machine Learning Course
- Lars Moen Storvik (up202508437@up.pt)
- Tina KovaÄeviÄ‡ (up202501724@up.pt)
- Zakariea Sharfeddine (up202501730@up.pt)

## ğŸ“„ License

Educational project for University of Porto.

